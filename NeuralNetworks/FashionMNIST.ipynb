{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to data\\FashionMNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26421880/26421880 [00:12<00:00, 2195012.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\FashionMNIST\\raw\\train-images-idx3-ubyte.gz to data\\FashionMNIST\\raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to data\\FashionMNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29515/29515 [00:00<00:00, 177089.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\FashionMNIST\\raw\\train-labels-idx1-ubyte.gz to data\\FashionMNIST\\raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to data\\FashionMNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4422102/4422102 [00:07<00:00, 570443.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\FashionMNIST\\raw\\t10k-images-idx3-ubyte.gz to data\\FashionMNIST\\raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to data\\FashionMNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5148/5148 [00:00<00:00, 332828.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\FashionMNIST\\raw\\t10k-labels-idx1-ubyte.gz to data\\FashionMNIST\\raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader #used to iterate through data and use it in our code.\n",
    "from torchvision import datasets # we will be using vision datasets. pytorch has domain specific datasets like text, vision, audio\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "# Dataset stores the samples and their corresponding labels, and DataLoader wraps an iterable around the Dataset.\n",
    "# Every TorchVision Dataset includes two arguments: transform and target_transform to modify the samples and labels respectively.\n",
    "\n",
    "#what does toTensor mean? tensor is a multidimensional array in pytorch\n",
    "# Download training data from open datasets.\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "# Download test data from open datasets.\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using loaded Datasets in our code through dataloader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n",
      "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]]])\n",
      "tensor([9, 2, 1, 1, 6, 1, 4, 6, 5, 7, 4, 5, 7, 3, 4, 1, 2, 4, 8, 0, 2, 5, 7, 9,\n",
      "        1, 4, 6, 0, 9, 3, 8, 8, 3, 3, 8, 0, 7, 5, 7, 9, 6, 1, 3, 7, 6, 7, 2, 1,\n",
      "        2, 2, 4, 4, 5, 8, 2, 2, 8, 4, 8, 0, 7, 7, 8, 5])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "# Here we define a batch size of 64, i.e. each element in the dataloader iterable will return a batch of 64 features and labels.\n",
    "# Create data loaders.\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "#we don't use numpy here?\n",
    "\n",
    "for X, y in test_dataloader:\n",
    "    print(f\"Shape of X [N, C, H, W]: {X.shape}\") #what are these four dimensions?\n",
    "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "    print(X)\n",
    "    print(y) #labels range from 0 to 9 for a 10 class classification\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating our model\n",
    "1. setting up which device to use\n",
    "2. defining model parameters\n",
    "3. 28*28 is a 2-d image's pixel dimensions. so in total there are 784 pixels, each being a number?\n",
    "4. Flattening of input before passing to the neural net:\n",
    "a. Dense layers expect a 1D input vector, so we need to flatten multi-dimensional data before passing it to them.\n",
    "b. flattening converts multi dimensional data into a single dimension.\n",
    "c. flattening preserves all the original information; it just reshapes it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Get cpu, gpu or mps device for training.\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "# Define model\n",
    "class NeuralNetwork(nn.Module):#we create a class that inherits from nn.Module.\n",
    "    def __init__(self): #constructor of our class.\n",
    "        super().__init__() #This calls the constructor of the parent class\n",
    "        self.flatten = nn.Flatten() #a function to flatten the input.\n",
    "        self.linear_relu_stack = nn.Sequential( # this is the core neural network function.\n",
    "            #we have a layer without any units, just for activation of prev layer. it simplifies calculations.\n",
    "            nn.Linear(28*28, 512), #first parameter means input size and second means no of units in the layer\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),# units in prev layer=input size of cur layer.\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10) # finally we have 10 neurons in the last layer.\n",
    "        )\n",
    "    #specify how data will pass through the network(forward pass) in the forward function.\n",
    "    # ie. first it will be flattened and the output would be the output of linear_relu_stack function.\n",
    "    def forward(self, x): \n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x) # This passes the flattened input through the stack of linear and ReLU layers.\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork().to(device)#To accelerate operations in the neural network, we move it to the GPU or MPS if available.\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimizing a model for training:\n",
    "1. optimizer\n",
    "2. loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training:\n",
    "In a single training loop, the model makes predictions on the training dataset (fed to it in batches), and backpropagates the prediction error to adjust the model’s parameters.\n",
    "- Does it backpropagate for each batch?\n",
    "a. both the forward pass and the backpropagation happen on a per-batch basis aka mini-batch gradient descent.\n",
    "b. Immediately after calculating the loss for a batch, backpropagation is performed for that same batch.\n",
    "c. This process (forward pass, loss calculation, backpropagation, parameter update) is repeated for each batch in an epoch.\n",
    "Again, what's the advantage of using batches?\n",
    "More frequent updates allow for faster convergence.\n",
    "Provides a balance between the efficiency of batch gradient descent and the noise of stochastic gradient descent.\n",
    "Allows for better generalization as the noise in the updates can help escape local minima.\n",
    "In pytorch, you can customize whether you want backprop to happen after a certain no of batches?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#why are we doing so much customization from our side?\n",
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, why so much customization from our side?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.300187  [   64/60000]\n",
      "loss: 2.289121  [ 6464/60000]\n",
      "loss: 2.276571  [12864/60000]\n",
      "loss: 2.269145  [19264/60000]\n",
      "loss: 2.249260  [25664/60000]\n",
      "loss: 2.223451  [32064/60000]\n",
      "loss: 2.227321  [38464/60000]\n",
      "loss: 2.190710  [44864/60000]\n",
      "loss: 2.187674  [51264/60000]\n",
      "loss: 2.156875  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 51.5%, Avg loss: 2.151225 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 2.159835  [   64/60000]\n",
      "loss: 2.148804  [ 6464/60000]\n",
      "loss: 2.097991  [12864/60000]\n",
      "loss: 2.115140  [19264/60000]\n",
      "loss: 2.064555  [25664/60000]\n",
      "loss: 2.005890  [32064/60000]\n",
      "loss: 2.035328  [38464/60000]\n",
      "loss: 1.950904  [44864/60000]\n",
      "loss: 1.954308  [51264/60000]\n",
      "loss: 1.890591  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 58.6%, Avg loss: 1.882500 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.914333  [   64/60000]\n",
      "loss: 1.884810  [ 6464/60000]\n",
      "loss: 1.773021  [12864/60000]\n",
      "loss: 1.813144  [19264/60000]\n",
      "loss: 1.712215  [25664/60000]\n",
      "loss: 1.659966  [32064/60000]\n",
      "loss: 1.681283  [38464/60000]\n",
      "loss: 1.576939  [44864/60000]\n",
      "loss: 1.599695  [51264/60000]\n",
      "loss: 1.505293  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 61.2%, Avg loss: 1.515517 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.578055  [   64/60000]\n",
      "loss: 1.545354  [ 6464/60000]\n",
      "loss: 1.402007  [12864/60000]\n",
      "loss: 1.475521  [19264/60000]\n",
      "loss: 1.359576  [25664/60000]\n",
      "loss: 1.353749  [32064/60000]\n",
      "loss: 1.367357  [38464/60000]\n",
      "loss: 1.286071  [44864/60000]\n",
      "loss: 1.322060  [51264/60000]\n",
      "loss: 1.232376  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 63.4%, Avg loss: 1.252154 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.323016  [   64/60000]\n",
      "loss: 1.306317  [ 6464/60000]\n",
      "loss: 1.149316  [12864/60000]\n",
      "loss: 1.257897  [19264/60000]\n",
      "loss: 1.130951  [25664/60000]\n",
      "loss: 1.158127  [32064/60000]\n",
      "loss: 1.176606  [38464/60000]\n",
      "loss: 1.106685  [44864/60000]\n",
      "loss: 1.151171  [51264/60000]\n",
      "loss: 1.073510  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 64.9%, Avg loss: 1.089437 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the model: \n",
    "state_dict(): serialize the internal state dictionary (containing the model parameters)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"FashionMNIST.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The process for loading a model includes re-creating the model structure and loading the state dictionary into it. because while saving, we only saved the model weights which are only reusable in a matching structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_8248\\1742528511.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"FashionMNIST.pth\"))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = NeuralNetwork().to(device)\n",
    "model.load_state_dict(torch.load(\"FashionMNIST.pth\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: \"Ankle boot\", Actual: \"Ankle boot\"\n"
     ]
    }
   ],
   "source": [
    "classes = [\n",
    "    \"T-shirt/top\",\n",
    "    \"Trouser\",\n",
    "    \"Pullover\",\n",
    "    \"Dress\",\n",
    "    \"Coat\",\n",
    "    \"Sandal\",\n",
    "    \"Shirt\",\n",
    "    \"Sneaker\",\n",
    "    \"Bag\",\n",
    "    \"Ankle boot\",\n",
    "]\n",
    "\n",
    "model.eval()\n",
    "x, y = test_data[0][0], test_data[0][1]\n",
    "with torch.no_grad():\n",
    "    x = x.to(device)\n",
    "    pred = model(x)\n",
    "    predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
    "    print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
